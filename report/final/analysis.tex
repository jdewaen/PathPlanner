\section{Experiments and Results}
\label{section:analysis}

\subsection{Scenarios}
Several different scenarios are used to test the algorithm. Each scenario takes place in a world with a certain distribution of obstacles, has a start and goal position, and a UAV with certain characteristics.
\par
There are three categories of scenarios, which will be discussed in section \ref{subsec:synth} to \ref{subsec:leuven}. All scenarios are tested in a general performance test (section \ref{subsec:gen-perf}) to get an overview of the performance of the algorithm with the default parameters. This test determines whether or not the algorithm scales to large and complex environments.\\
In the other tests, only one scenario of each category has been used. Section \ref{subsec:agility} tests the performance of the algorithm as the characteristics of the UAV change. Section \ref{subsec:stability} looks at the stability of the algorithm. These tests should provide further insight on the limitations of the algorithm.\\

Sections \ref{subsec:cutting} to \ref{subsec:approach-margin} look at the effects of different parameters on both the performance of the algorithm and the quality of the trajectory. Sensible default parameters have been chosen. However, changing these parameters provides deeper insights in the characteristics of the algorithm.

All tests were executed on an Intel Core i5-4690k running at 4.4GHz with 16GB of 1600MHz DDR3 memory. The reported times are averages of 5 runs, unless stated otherwise. The machine runs on Windows 10 using version 12.6 of IBM CPLEX. Table \ref{table:params} show the default parameters as used in all tests.

\begin{figure}[h]
\centering
\begin{tabular}{ l  r | l r }
grid size 			& $2m$ 	& turn tolerance 		& $2$ \\
approach multiplier & $2$ 	& population size 		& $ 10$ \\
\# generations 		& $25$ 	& max. nudge distance 	& $5m$\\
min. \# vertices 	& $ 4$ 	& max. \# vertices 		& $12$ \\
P(add vertex) 		& $0.1$ & P(remove vertex) 		& $0.1$  \\
max nudge attempts 	& $15$ 	& $ T_{max}$ 			& $5s$ \\
time step size 		& $0.2s$& position tolerance & $3$ \\
CPLEX max solve time & $120s$ & CPLEX max delta & $1$ \\
time limit multiplier & $1.5$ & max segment time & $3s$\\
%approach margin, maxsegment time
%fps
%pop, gens, mutrate, nudge dist, minpoints-maxpoints, addprob, removeprob
\end{tabular}
\caption{The parameters used for testing}
\label{table:params}
\end{figure}
\clearpage
\subsubsection{Synthetic Scenarios}
\label{subsec:synth}
The synthetic scenarios have small, handmade worlds. They have few obstacles, but the obstacles are laid out in a way that makes them challenging to solve. There are two "Up/Down" scenarios, small (Figure \ref{fig:bench-small}) and large (Figure \ref{fig:bench-large}), in which the UAV has to move in a zig-zag pattern to reach its goal. The difference between those scenarios is the amount of obstacles, which also changes the amount of zig-zags required. These scenarios are built to see how the algorithm handles sharp turns. There is also a spiral scenario in which the UAV must go in an outwards spiral (Figure \ref{fig:spiral}.\\
The large Up/Down scenario represents this category in the tests. Table \ref{table:uav-synth} shows the properties of the UAV.

\begin{table}[h]
\centering
\begin{tabular}{ c | c | c }
$v_{max}$ ($ms^{-1}$)	& $a_{max}$ ($ms^{-2}$) 	& radius ($m$) 	 \\
\hline
$3$ & $4$ 	& $0.5$ \\
\end{tabular}
\caption{The UAV properties for the synthetic scenarios}
\label{table:uav-synth}
\end{table}

\begin{figure}
	\centering
	
	\begin{subfigure}[t]{0.5\textwidth}
        		\includegraphics[width=\textwidth]{img/bench-small}
        		\caption{}
        		\label{fig:bench-small}
	\end{subfigure}
		
	\begin{subfigure}[t]{0.6\textwidth}
        		\includegraphics[width=\textwidth]{img/bench-large}
        		\caption{}
        		\label{fig:bench-large}
	\end{subfigure}	
	
	\begin{subfigure}[t]{0.5\textwidth}
        		\includegraphics[width=\textwidth]{img/spiral}
        		\caption{}
        		\label{fig:spiral}
	\end{subfigure}
        
    \caption{The synthetic scenarios}\label{fig:synth-scens}
\end{figure}
\clearpage
\subsubsection{San Francisco Scenarios}
\label{subsec:sf}
The San Francisco scenarios contain a world which is based on a map of San Francisco. There are 2 small San Francisco scenarios (Figure \ref{fig:sf-small-1} and \ref{fig:sf-small-2}), which both share the same 1km by 1km area of San Francisco but have different start and goal locations. There is also a larger San Francisco scenario which takes places on a 3km by 3km world (Figure \ref{fig:sf-large}). \\
All obstacles in the San Francisco dataset are grid-aligned rectangles, laid out in typical city blocks. Because of this, density of obstacles is predictable. These scenarios showcase that the algorithm can scale to realistic scenarios with much more obstacles than is typically possible with a MILP approach. \\
The first small San Francisco scenario is used to represent this category in the tests. Table \ref{table:uav-sf} shows the properties of the UAV and Figure \ref{fig:sf-zoom} shows a zoomed-in view of the first small scenario. 


\begin{table}[h]
\centering
\begin{tabular}{ c | c | c }
$v_{max}$ ($ms^{-1}$)	& $a_{max}$ ($ms^{-2}$) 	& radius ($m$) 	 \\
\hline
$10$ & $15$ 	& $2.5$ \\
\end{tabular}
\caption{The UAV properties for the San Francisco scenarios}
\label{table:uav-sf}
\end{table}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{sf-zoom}
	\caption{A zoomed-in view of the first small the San Francisco scenario}
	\label{fig:sf-zoom}
\end{figure}


\begin{figure}
	\centering
	
	\begin{subfigure}[t]{0.46\textwidth}
        		\includegraphics[width=\textwidth]{img/sf-small-1}
        		\caption{San Francisco Small 1}
        		\label{fig:sf-small-1}
	\end{subfigure}
	\hfil	
	\begin{subfigure}[t]{0.46\textwidth}
        		\includegraphics[width=\textwidth]{img/sf-small-2}
        		\caption{San Francisco Small 2}
        		\label{fig:sf-small-2}
	\end{subfigure}	
	\par
	\begin{subfigure}[t]{0.8\textwidth}
        		\includegraphics[width=\textwidth]{img/sf-large}
        		\caption{San Francisco Large}
        		\label{fig:sf-large}
	\end{subfigure}
        
    \caption{The San Francisco scenarios}\label{fig:sf-scens}
\end{figure}

\clearpage
\subsubsection{Leuven Scenario}
\label{subsec:leuven}
The Leuven scenarios contain a world based on a map of the city of Leuven. This is an old city with a very irregular layout. The dataset, provided by the local government\footnote{\url{https://overheid.vlaanderen.be/producten-diensten/basiskaart-vlaanderen-grb}}, also contains full polygons instead of the grid-aligned rectangles of the San Francisco dataset. While most buildings in the city are low enough so a UAV could fly over, it presents a very difficult test case for the path planning algorithm. The density of obstacles varies greatly and is much higher than in the San Francisco dataset across the board.

\begin{table}[h]
\centering
\begin{tabular}{ c | c | c }
$v_{max}$ ($ms^{-1}$)	& $a_{max}$ ($ms^{-2}$) 	& radius ($m$) 	 \\
\hline
$10$ & $15$ 	& $1$ \\
\end{tabular}
\caption{The UAV properties for the Leuven scenarios}
\label{table:uav-leuven}
\end{table}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{leuven-zoom}
	\caption{A zoomed-in view of the first small the Leuven scenario}
	\label{fig:sf-zoom}
\end{figure}



\begin{figure}
	\centering
	
	\begin{subfigure}[t]{0.46\textwidth}
        		\includegraphics[width=\textwidth]{img/leuven-small-1}
        		\caption{Leuven Small 1}
        		\label{fig:leuven-small-1}
	\end{subfigure}
	\hfil	
	\begin{subfigure}[t]{0.46\textwidth}
        		\includegraphics[width=\textwidth]{img/leuven-small-2}
        		\caption{Leuven Small 2}
        		\label{fig:leuven-small-2}
	\end{subfigure}	
	\par
	\begin{subfigure}[t]{0.8\textwidth}
        		\includegraphics[width=\textwidth]{img/leuven-large}
        		\caption{Leuven Large}
        		\label{fig:leuven-large}
	\end{subfigure}
        
    \caption{The Leuven scenarios}\label{fig:sf-scens}
\end{figure}


%\begin{figure}
%	\centering
%	
%	\begin{subfigure}[t]{0.74\textwidth}
%        		\includegraphics[width=\textwidth]{img/benchmarkfull}
%        		\caption{}
%	\end{subfigure}
%		
%	\begin{subfigure}[t]{0.70\textwidth}
%        		\includegraphics[width=\textwidth]{img/SF}
%        		\caption{}
%	\end{subfigure}	
%	
%	\begin{subfigure}[t]{0.70\textwidth}
%        		\includegraphics[width=\textwidth]{img/leuven}
%        		\caption{}
%	\end{subfigure}
%        
%    \caption{These are the three different worlds which were tested. The top image shows the large Up/Down scenario. The middle image shows the small San Francisco scenario. Note how the obstacles are only grid-aligned rectangles laid out in a grid pattern. The bottom image shows the small Leuven scenario. The obstacles are polygons and distributed in a much more irregular pattern compared to the San Francisco scenario.}\label{fig:scenarios}
%\end{figure}
%
%
%\begin{figure}
%\begin{tabular}{ l l l l l l l l l }
% scenario & \# obstacles & world size & path length & \# segments & Theta* time & Gen. Al. time & MILP time & score \\ 
% \hline
%Up/Down Small & 5 &  25m x 20m & 88m  & 7 & 0.09s & 1.10s & 20.8s & 26.6s\\
%Up/Down Large & 9 & 40m x 20m &  146m & 11 & 0.14s & 1.62s & 40.1s & 43.6s \\
%SF Small & 684 & 1km x 1km & 1392m & 28 & 2.04s & 9.56s & 59.2s & 105.7s \\
%SF Large & 6580 & 3km x 3km & 4325m  & 84 & 18.14s & 18.21s & 231s & 316.0s\\
%Leuven Small & 3079 & 1km x 1km & 1312m & 29 &  2.29s & 29.83s & 152s  & 95.9s \\
%Leuven Large & 18876 & 3km x 3km & 3041m & 61 & 18.14s & 83.69s & 687s & 217.6s \\
%
%\end{tabular}
%\caption{The experimental results for the different scenarios}
%\label{table:results}
%\end{figure}


\clearpage
%\subsection{Convexity of Search Space}
%
%\begin{figure}
%	\centering
%	\begin{subfigure}[t]{1\columnwidth}
%        		\includegraphics[width=\textwidth]{small-bench-flat}
%        		\caption{}
%        		\label{fig:convex-straight}
%	\end{subfigure}
%	\par\bigskip
%	\begin{subfigure}[t]{1\columnwidth}
%        		\includegraphics[width=\textwidth]{small-bench-diag}
%        		\caption{}
%        		 \label{fig:convex-diag}
%	\end{subfigure}	
%	\par\bigskip
%	\begin{subfigure}[t]{0.8\columnwidth}
%        		\includegraphics[width=\textwidth]{small-bench}
%        		\caption{}
%        		 \label{fig:convex-full}
%	\end{subfigure}	
%    \caption{}
%    \label{fig:}     
%\end{figure}
%\begin{figure}[]
%	\centering
%	\includegraphics[width=\textwidth]{convexity-data}
%	\caption{convexity data}
%	\label{fig:convex-data}
%\end{figure}
%The convexity of the search space plays a large role in the difficulty of a MILP problem. My approach is built entirely around the idea of keeping the search space as convex as possible in each segment. To analyze  the importance of convexity, I tested three scenarios without any form of preprocessing. These scenarios are designed so the optimal trajectory has roughly the same duration in each scenario. The scenarios also each have 5 grid aligned rectangles as obstacles.\\
%As a result, MILP problems for all three scenarios have nearly identical amounts of integer variables. The difference between these scenarios is the convexity of the search space. \\
%In the first scenario, the obstacles are not in the way of the UAV. The UAV can move in a straight line from the start position to its goal. In the second scenario, two of the obstacles are slightly in the way. The UAV is forced to make slight turns near the start and end of the trajectory. However, most of the trajectory is still straight. In the third scenario, the vehicle has to slalom around every obstacle.\\
%
%\subsubsection{Results}
%
%\subsubsection{Interpretation}
%Even though all scenarios have nearly identical amounts of time steps, integer variables and obstacles, the solve time varies greatly. This confirms the core assumption behind my approach: The convexity of the search space plays a larger role in the performance than the amount of integer variables.

\clearpage
\subsection{General Performance}
\label{subsec:gen-perf}
\begin{table}[]
\centering
\begin{tabular}{ l | r | l | r | r}
Scenario name & \# obstacles & world size & path length (m)  & \# segments \\
\hline
Up/Down Small 	& 5 	& 25m x 20m 	& 88 	& 7   \\ 
Up/Down Large 	& 9 	& 40m x 20m 	& 146 	& 11  \\
Spiral		 	& 11 	& 30m x 30m 	& 96 	& 10  \\
SF Small 1		& 684 	& 1km x 1km 	& 1392 	& 34  \\
SF Small 2		& 684 	& 1km x 1km 	& 1490 	& 38  \\
SF Large	 	& 6580 	& 3km x 3km 	& 4325 	& 107 \\
Leuven Small 1 	& 3079 	& 1km x 1km 	& 1312 	& 34  \\
Leuven Small 2	& 3079 	& 1km x 1km 	& 864 	& 22  \\
Leuven Large 	& 18876	& 3km x 3km 	& 3041 	& 78  \\
\end{tabular}
\caption{Some information about the scenarios tested.}
\label{table:gen-data}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{ l | r | r | r | r || r}
Scenario name & Theta* (s) & GA (s) & MILP (s)  & total (s) & score (s) \\
\hline
Up/Down Small 	& 0.00 	& 0.33 	& 10.48 	& 10.97 	& 27.24	\\ 
Up/Down Large 	& 0.00 	& 0.65 	& 17.95 	& 18.87 	& 44.76	\\
Spiral		 	& 0.01 	& 1.06	& 7.17		& 8.46 		& 28.72	\\
SF Small 1		& 1.37 	& 7.68 	& 32.81 	& 42.43 	& 106.20\\
SF Small 2		& 1.82 	& 7.98	& 36.81 	& 47.32 	& 114.36\\
SF Large	 	& 15.88	& 15.41	& 75.44 	& 108.28 	& 325.10\\
Leuven Small 1 	& 1.51 	& 23.49	& 135.86	& 161.85	& 97.44	\\
Leuven Small 2	& 0.53 	& 14.00	& 62.03 	& 76.99 	& 65.52	\\
Leuven Large 	& 14.65	& 67.55	& 460.46 	& 544.73 	& 227.27\\
\end{tabular}
\caption{A breakdown of the execution time for each scenario, as well as the score of the trajectory.}
\label{table:gen-results}
\end{table}

\clearpage
\subsection{Agility of the UAV}
\label{subsec:agility}
The properties of the segments strongly rely on the agility of the UAV. The size of the segments is determined by the maximum acceleration distance of the UAV. This is the distance the UAV needs to accelerate from zero to its maximum velocity, or decelerate from the maximum velocity to zero. \\
In this experiment, I tested relation between the maximum velocity and the maximum acceleration of the UAV. I used the large Up/Down scenario, the small San Francisco scenario and the small Leuven scenario. For each scenario I tested nine configurations of the vehicle: Every combination between three different maximum velocities and three different maximum accelerations.\\
TODO: add \# segments

\begin{figure}
\includegraphics[width=\textwidth]{img/agility1}
caption{}
\label{fig:agility-times}
\end{figure}
Even though some combinations did not finish for the larger scenarios, the results are relatively consistent across all three scenarios:\\
Within each speed category, a higher acceleration always reduces solve times. This is as expected, because a higher acceleration will reduce the expansion distance for the segments, making them both shorter in time as well as smaller so less obstacles are expected to be modeled.\\
Increasing the velocity for the low and medium acceleration tends to make things slower.
Low velocity and high acceleration always score well





\clearpage
\subsection{Stability}
\label{subsec:stability}
\begin{figure}[]
	\centering
	\includegraphics[width=\textwidth]{stability-data}
	\caption{stability data}
	\label{fig:stability-data}
\end{figure}
Stability is an important property of an algorithm. When the same problem is solved several times, the algorithm should not occasionally fail to solve the problem or require a wildly different amount of time to solve that problem. \\

This experiment aims to measure the stability of the algorithm. Each of the testing scenarios is executed 50 times. \\

Even though the each sub-problem should ensure that the next segment can be solved, occasionally this was not the case as demonstrated in Figure \ref{fig:transition-fail}. This may be due to a bug, or some assumption which is false. I did not manage to find the cause for this, but overlapping the segments should mitigate this problem. For this reason, each scenario was also tested with an overlap of 5 time steps per segment.
\begin{figure}[]
	\centering
	\includegraphics[width=0.5\textwidth]{transition-fail}
	\caption{A case where the transition fails}
	\label{fig:transition-fail}
\end{figure}





\clearpage
\subsection{Cornercutting}
\label{subsec:cutting}
A trajectory that allows corner cutting cannot be considered safe. However, additional constraints are required to prevent this from happening. This experiment attempts to measure the impact of the corner cutting prevention.


\subsubsection{Result}
\begin{figure}[]
	\centering
	\includegraphics[width=\textwidth]{corner-cutting-data}
	\caption{corner cutting data}
	\label{fig:corner-data}
\end{figure}

The performance impact caused by preventing corner cutting seems minimal (TODO: more precise!).


\clearpage
\subsection{Linear approximation}
\label{subsec:lin-approx}
The velocity and acceleration of the UAV are limited to some finite value. Because both of those quantities are vectors, that maximum can only be approximated with linear constraints. More constraints are needed to model this more accurately which can allow for faster solutions. However, more constraints also have a performance cost. This experiment analyses the trade-off that needs to be made.
\begin{figure}[]
	\centering
	\includegraphics[width=\textwidth]{linear-data}
	\caption{linear approx data}
	\label{fig:linear-approx-data}
\end{figure}



\subsubsection{Results}
In all cases, increasing the amount of vertices used to approximate the 2-norm also increases the solve time. Increasing the amount of vertices did not have a measurable effect on the score of the trajectory (EXCEPT LEUVEN?), 

\clearpage
\subsection{Time step size}
\label{subsec:timestep}
The time step size determines how many time steps are used in each MILP problem. The discretized time steps are samples at regular intervals of the continuous trajectory that the UAV would actually travel in the real world. As a result, the trajectory defined by those time steps is a piece-wise linear approximation of this smooth, real world trajectory. \\
As the size of each step goes to zero, the approximation becomes more accurate. This also means that the trajectory should become faster, since the UAV can be controlled more precisely through time. This allows for more aggressive maneuvers. \\
However, adding more time steps increases the amount of integer variables and constraints. This comes at a performance cost. \\
In this experiment, three different time step sizes are tested. The $0.2s$ default value, as well as $0.1s$ and $0.5s$ are tested.
\begin{figure}[]
	\centering
	\includegraphics[width=\textwidth]{timestep-data}
	\caption{time step data}
	\label{fig:timestep-data}
\end{figure}
\subsubsection{Results}
The time step size has a dramatic impact on performance. For the benchmark scenario, each increase in the amount of time steps resulted in around 14x the computation time. For the San Francisco scenario, that is around 6-7x. In both cases the trajectory time improved with more time steps as well, although the difference is smaller when going from $0.2s$ to $0.1s$ compared to $0.5s$ to $0.2s$.






\clearpage
\subsection{Max Time}
\label{subsec:maxtime}
\begin{figure}[]
	\centering
	\includegraphics[width=\textwidth]{maxtime-data}
	\caption{maxtime data}
	\label{fig:maxtime-data}
\end{figure}
For each sub-problem, the amount of time steps to model needs to be determined in advance. The algorithm calculates an estimated upper bound for the time (and thus the amount of time steps). In the ideal case, this upper bound is equal to the time needed for the optimal trajectory. However, if the upper bound is too low, no solution can be found.\\

This experiment looks at the importance of a low upper bound on the time needed. By default, the estimated upper bound is multiplier by 1.5 to ensure enough time steps are available. A multiplier of 1 is also test, along with a multiplier of 2. \\

\subsubsection{Results}
The time needed to solve the scenarios is heavily influenced by maximum time given. For these scenarios, the default multiplier of 1.5 seems unnecessary and could be lowered to 1 without issues. Increasing the multiplier to 2 nearly doubles the solve time across the board.


\clearpage
\subsection{Approach Margin}
\label{subsec:approach-margin}
\begin{figure}[]
	\centering
	%\includegraphics[width=\textwidth]{approach-data}
	\caption{approach data}
	\label{fig:approach-data}
\end{figure}

\clearpage
\subsection{Genetic Algorithm Parameters}
\label{subsec:ga-params}
tweak parameters...


%\clearpage
%\subsection{Issues}
%
%\subsubsection{Active region}
%often good results, but sometimes cuts corner too close
%
%\subsubsection{Segment transitions}
%small epsilon -> uav needs to slow down, forces trajectory very close to path
%large epsilon + line -> uav tends to curve and still slow down close to transition, cause unknown?
%						-> cause: needs to be able to stop?                        
%occasional failures: jerk only? TEST!!
%transition itself is weak point of approach. Possible way to solve: resolve transition area based on a bit before and after transition
%
%\subsubsection{Maximum time for segment}
%Finding maximum time for a segment needs to overestimate: more time steps cause longer solve times
%Solution: generate path at lower temporal resolution to find accurate time needed. Could improve solve time





% \subsection{Safety}
% guaranteed by constraints, however:\\
% no incentive to stay away from walls. Can increase vehicle size, but prevents occasionally getting closer for a short while.\\
% \subsection{Stability and Performance}
% -maxtime (max length of segment)\\
% - approach margin: larger -> better approach, longer solve time\\
% - tolerance: larger -> when corners are close, merge faster: more execution time\\
% - position tolerance: larger -> smoother path, strays further from preprocessed path so needs to backtrack more often\\
% - backtracking effect?\\
% -can quickly recalculate based on measured state? IMPLEMENT WARM START EXPERIMENT?\\


\section{Discussion}
The goal of this thesis is build a scalable approach for MILP trajectory planning. The target vehicles are multirotor UAVs, so the results in the previous section need to be analyzed in that context. \\
The first step is analyzing whether or not the approach is actually scalable enough when planning the trajectory for this kind of vehicle through complex environments.\\
Afterwards, the other experiments demonstrate the importance of some of the parameters used in the algorithm. The results provide insight in the limitations of the current approach, and how it may be improved in the future.

\subsection{Research question result}


The general performance results show that the algorithm is capable of planning a long trajectory through complex environments. Even for the smallest scenarios, the solver struggles to find a trajectory without preprocessing. With my algorithm, the UAV can successfully navigate an entire city. \\
The convexity test demonstrates that convexity of the search space is indeed a large factor. This supports the assumption that my entire algorithm is built upon: Maintaining convexity as much as possible is required to make the algorithm scale. \\
The stability test shows that, for the most part, my segmentation approach preserves stability. There still are some issues around the transitions between segments, but they can be eliminated by slightly overlapping the segments. This overlap comes at a performance cost, but it also improves the quality of the trajectory. Overall I am not entirely satisfied with the stability of my current implementation, however I do believe the small issues around segment transitions can be resolved. \\\\

The results show a large improvement in scalability in certain realistic scenarios, but the choice of those scenarios has drastically impacted the algorithm I have developed.\\

During development, I have always used realistic approximations of the capabilities of multirotor UAVs. Those can reach high accelerations but have relatively low maximum velocities compared to what fixed-wing aircraft can achieve. This makes those vehicles very agile, which is one of the contributing factors to their recent popularity. \\
The assumption of this agility means that my algorithm cannot be applied to UAVs which do not have that property. One of the properties my algorithm uses often is the maximum acceleration distance, which is the distance in which the UAV can always come to a complete stop. This works fine with multirotor UAVs, but is a meaningless concept when dealing with fixed-wing UAVs which cannot stop at all during flight. \\
However, those kinds of low-agility UAVs are unlikely to be deployed at low altitudes in dense city centers exactly because they lack agility. Even with perfect planning, cities are very unpredictable places. An multirotor UAV is much more likely to be able to safely react to an unexpected obstacle than a fixed-wing UAV. \\
While I picked out fixed-wing UAVs as an example, the same arguments hold for any kind of UAV that either cannot hover or has low agility. Some UAVs may be able to hover, but are not very agile due to a high maximum velocity and low acceleration. In this case, the agility can be improved by reducing the maximum velocity.\\ \\

The density of obstacles is also an extremely important factor. The Leuven scenario is significantly harder than the San Francisco scenario because the obstacles are smaller and closer together. Not only are the obstacles closer together, but they are also polygons and can have many more edges per obstacle. For scenarios where the obstacles are significantly denser or complex than in the Leuven scenario, the approach may not improve the performance enough. \\
On the other hand, the Leuven map is much more detailed than is required for navigation. Many obstacles could be merged together without a significant on possible trajectories. The obstacles could also be simplified, reducing the amount of edges per obstacle. Given that the Leuven map is unprocessed except for calculating the convex hull of each obstacle, the algorithm should be able to handle most real world maps when properly prepared.

Given these considerations, I conclude that my approach meets the basic requirements. The assumptions behind the design of the algorithm seem to be valid based on experiments.

\subsection{Factors}
While the chosen parameter values allow the algorithm to scale well, different values may be chosen to find a different balance between performance and solution quality. \\
The corner cutting prevention makes the trajectory slightly slower, but that is to be expected since cutting a corner is faster than going around. The performance does take a hit, but the extent is minimal. The corner cutting prevention constraints seem certainly worth being enabled. \\
The 2-norm approximation has a slightly larger effect on performance. However, there does not seem to be an impact on the trajectory speed. This value could be reduced for a small performance gain. \\ \\

The time step size and maximum time both have a dramatic impact on the performance. The time step size should be no smaller than necessary, and the maximum time should be as small as possible. They are by far the most important performance factors. As a result, further improvements on performance should focus on these factors. A way to improve performance may be solving each segment twice: Once with a high time step size and a conservative maximum time, and another time with a smaller time step size and a very tight maximum time. The first run quickly and provides a tight upper limit on the amount of time needed for the segment. The second run would also run significantly faster, since the amount of time steps modeled is much closer to what is actually needed. Due to a lack of time, I was unable to implement this. \\

The approach margin data is probably the strangest. Going from a low to medium approach margin increases the solve time and improves the trajectory, as expected. However, increasing the approach margin again actually decreases the solve time again, as well as reducing the quality of the trajectory. This is unexpected since a approach margin should lead to larger segments which take longer to solve. The larger segments should also improve the quality of the solution because corners can be taken more efficiently, yet the the opposite happens in the data. TODO: find answer?






%\subsection{evolution of understanding}
%One of the main recurring patterns in my thesis is the concept of convexity. Early on in the thesis I was not aware of the importance of convexity. The worst case performance of MILP depends on the amount of integer variables, so my early attempts at improving performance were focused on reducing the amount of integer variables. \\
%Segmenting the trajectory planning problem into smaller pieces was part of that effort to reduce the amount of integer variables. However, at the time I was not aware of the relation between turns and convexity. I decided to focus on the turns from a purely pragmatic stand point. Each turn is a maneuver. To find the optimal trajectory for that maneuver, the maneuver should be solved in a single segment. Based on this idea, the core of my algorithm was built. \\
%This was functional by the end of the first semester. By this time, I had figured out that obstacles necessarily cause a non-convex search space. I used this insight to separate obstacles on the inside of turns from those on the outside. The algorithm produced promising results, but I did not fully understand ....TODO?
%
%However, the algorithm only supported grid aligned rectangles for obstacles with the San Francisco dataset. To really test the algorithm, it needed to support  arbitrary polygons as obstacles. Implementing this caused many small and large problems. There were many implicit assumptions that worked with the grid-aligned rectangles. I also ran into scaling issues with my preprocessing algorithm.

\subsection{critical review}